{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6825ae",
   "metadata": {},
   "source": [
    "# Cline Prompt Learning Optimization on SWE-bench - Act Mode\n",
    "\n",
    "<p align=\"left\">\n",
    "  <span style=\"display: inline-block; width: 500px; height: auto; overflow: hidden; vertical-align: middle;\">\n",
    "    <img src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/images/phoenix.jpeg\" style=\"margin: -10px -50px; width: 600px;\" />\n",
    "  </span>\n",
    "  <img src=\"https://storage.googleapis.com/arize-phoenix-assets/assets/images/cline.png\" width=\"200\" style=\"vertical-align: middle;\" />\n",
    "</p>\n",
    "\n",
    "This notebook demonstrates how we used Prompt Learning to optimize Cline's performance on the SWE-bench dataset in **Act Mode**. Cline is a popular and powerful open-source coding agent. We look to improve its performance on SWE-bench by optimizing its **rules**, which are user specified instructions that Cline appends to its system prompt. \n",
    "\n",
    "[More on Cline](https://www.google.com/search?q=cline&sca_esv=764700c983d0c1df&sxsrf=AE3TifOTqxMNetNu45T7bn53deGE6bPn3w%3A1759280858717&ei=2n7caKLCK6XK0PEPpuCv6AY&ved=0ahUKEwiil5P154GQAxUlJTQIHSbwC20Q4dUDCBA&uact=5&oq=cline&gs_lp=Egxnd3Mtd2l6LXNlcnAiBWNsaW5lMgoQIxiABBgnGIoFMgoQIxiABBgnGIoFMgoQIxiABBgnGIoFMhMQLhiABBixAxjRAxhDGMcBGIoFMhMQLhiABBixAxjRAxgUGIcCGMcBMgoQABiABBhDGIoFMgoQABiABBhDGIoFMgUQABiABDIFEAAYgAQyChAAGIAEGEMYigVIkw1Q8QNYpgxwA3gBkAEAmAG2AaABkAKqAQMxLjG4AQPIAQD4AQGYAgWgApwCwgIKEAAYsAMY1gQYR8ICDRAAGIAEGLADGEMYigXCAg4QABiwAxjkAhjWBNgBAcICDhAuGLADGLgGGMgD2AEBwgIQEC4YgAQY0QMYQxjHARiKBZgDAIgGAZAGE7oGBggBEAEYCZIHAzQuMaAHwhiyBwMxLjG4B5QCwgcDMC41yAcJ&sclient=gws-wiz-serp#:~:text=Cline%20%2D%20AI%20Coding,https%3A//cline.bot)\n",
    "\n",
    "[More on Prompt Learning](https://arize.com/blog/prompt-learning-using-english-feedback-to-optimize-llm-systems/)\n",
    "\n",
    "## Act Mode - Real Code Execution\n",
    "\n",
    "Unlike Plan Mode, this notebook runs Cline in **Act Mode**, where Cline actually edits the codebase and generates patches. We then run the SWE-bench tests to compute a definitive accuracy of whether Cline made the correct edits. This provides ground truth evaluation of Cline's performance.\n",
    "\n",
    "In Act Mode, Cline:\n",
    "1. Analyzes the problem statement\n",
    "2. Explores the codebase\n",
    "3. Makes actual code edits\n",
    "4. Generates patches\n",
    "5. Has its patches validated against the SWE-bench test suite\n",
    "\n",
    "## SWE Bench + Cline Setup\n",
    "\n",
    "**Please visit README.md and complete all the Setup before running this notebook!**\n",
    "\n",
    "## Phoenix Setup\n",
    "\n",
    "Visit phoenix.arize.com and sign-in/create account.\n",
    "\n",
    "## Important Note\n",
    "\n",
    "Running this notebook is computationally intensive and expensive as it involves:\n",
    "- Multiple API calls to Claude for each SWE-bench instance\n",
    "- Actually cloning repositories and running tests in isolated environments\n",
    "- Running SWE-bench harness to validate patches\n",
    "\n",
    "Consider adjusting the training and test set sizes based on your requirements, budget constraints, and computational resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a943e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qq swebench arize-phoenix arize-phoenix-client pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c793e179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cline/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-10 16:14:15,552 - phoenix.config - INFO - ðŸ“‹ Ensuring phoenix working directory: /Users/priyanjindal/.phoenix\n",
      "2025-10-10 16:14:15,571 - phoenix.inferences.inferences - INFO - Dataset: phoenix_inferences_84e73990-f4fd-4283-91e2-b05b01d3d322 initialized\n"
     ]
    }
   ],
   "source": [
    "from run_act import run_act\n",
    "from swebench.harness.utils import load_swebench_dataset\n",
    "import random\n",
    "from evals_act import evaluate_results\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import getpass\n",
    "\n",
    "notebook_dir = Path().absolute()\n",
    "sys.path.insert(0, str(notebook_dir.parent.parent))\n",
    "from optimizer_sdk.prompt_learning_optimizer import PromptLearningOptimizer\n",
    "\n",
    "sys.path.insert(0, str(notebook_dir.parent))\n",
    "from constants import CLINE_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962e449",
   "metadata": {},
   "source": [
    "## API Keys\n",
    "\n",
    "Set up your API keys for OpenAI, Anthropic, and Arize. If not already in your environment, you'll be prompted to enter them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0708f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\") or getpass.getpass(\"Enter your Anthropic API key: \")\n",
    "os.environ[\"PHOENIX_API_KEY\"] = os.getenv(\"PHOENIX_API_KEY\") or getpass.getpass(\"Enter your Phoenix API key: \")\n",
    "HOSTNAME = os.getenv(\"PHOENIX_HOSTNAME\") or getpass.getpass(\"Enter your Phoenix hostname: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d137d39",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "- LOOPS: number of Prompt Learning loops. How many times you want to optimize your prompt.\n",
    "- TRAIN_SIZE: size of training set.\n",
    "- TEST_SIZE: size of test set.\n",
    "- WORKERS: SWE-bench is set up to run in parallel, with however many workers you specify. Set this relative to your machine's capabilities and your Claude rate limits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44c9566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOPS = 5\n",
    "TRAIN_SIZE = 150\n",
    "TEST_SIZE = 150\n",
    "WORKERS = 52"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f7ad9",
   "metadata": {},
   "source": [
    "## Cline Environment Configuration\n",
    "\n",
    "Set environment variables for Cline to run properly in Act Mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c167a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CLINE_DISABLE_TERMINAL_REUSE\"] = \"1\"\n",
    "os.environ[\"CLINE_DEFAULT_TERMINAL_PROFILE\"] = \"bash\"\n",
    "os.environ[\"CLINE_SHELL_INTEGRATION_TIMEOUT_SEC\"] = \"10\"\n",
    "os.environ[\"CLINE_STANDALONE_CAPTURE_STDIO\"] = \"1\"\n",
    "os.environ[\"CLINE_SKIP_RESUME_CONFIRMATION\"] = \"1\"\n",
    "os.environ[\"CLINE_AUTO_FOLLOWUP\"] = \"1\"\n",
    "os.environ[\"CLINE_ENVIRONMENT\"] = \"local\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe74fd",
   "metadata": {},
   "source": [
    "## Train/Test Datasets\n",
    "\n",
    "This code splits SWE-bench Lite into train/test splits.\n",
    "\n",
    "The train set will be used to optimize the ruleset, while the test set will be used to measure the success of optimized rulesets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28654d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SWE-bench/SWE-bench_Lite\"\n",
    "dataset = load_swebench_dataset(dataset_name, \"test\")\n",
    "ids = [inst[\"instance_id\"] for inst in dataset]\n",
    "random.seed(40)\n",
    "random.shuffle(ids)\n",
    "train_ids = ids[:TRAIN_SIZE]        \n",
    "test_ids = ids[len(ids) - TEST_SIZE:]\n",
    "by_id = {ex[\"instance_id\"]: ex for ex in dataset}\n",
    "train_dataset = [by_id[i] for i in train_ids]\n",
    "test_dataset  = [by_id[i] for i in test_ids]\n",
    "\n",
    "train_pd = pd.DataFrame(train_dataset)\n",
    "test_pd  = pd.DataFrame(test_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577508b2",
   "metadata": {},
   "source": [
    "## Upload Datasets to Phoenix\n",
    "\n",
    "Upload datasets to Arize for experiment tracking and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4752106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 17:48:05,715 - phoenix.client.resources.datasets - INFO - Uploading dataset...\n",
      "2025-10-10 17:48:06,346 - httpx - INFO - HTTP Request: POST https://app.phoenix.arize.com/s/cline-priyan/v1/datasets/upload?sync=true \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:48:06,417 - httpx - INFO - HTTP Request: GET https://app.phoenix.arize.com/s/cline-priyan/v1/datasets/RGF0YXNldDoxNA%3D%3D \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:48:06,559 - httpx - INFO - HTTP Request: GET https://app.phoenix.arize.com/s/cline-priyan/v1/datasets/RGF0YXNldDoxNA%3D%3D/examples?version_id=RGF0YXNldFZlcnNpb246MTQ%3D \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 17:48:06,612 - phoenix.client.resources.datasets - INFO - Dataset uploaded successfully. ID: RGF0YXNldDoxNA==, Version: RGF0YXNldFZlcnNpb246MTQ=\n",
      "2025-10-10 17:48:06,636 - phoenix.client.resources.datasets - INFO - Uploading dataset...\n",
      "2025-10-10 17:48:06,748 - httpx - INFO - HTTP Request: POST https://app.phoenix.arize.com/s/cline-priyan/v1/datasets/upload?sync=true \"HTTP/1.1 409 Conflict\"\n"
     ]
    },
    {
     "ename": "DatasetUploadError",
     "evalue": "Dataset upload failed: Dataset with the same name already exists: name='Cline Act Mode: SWE-bench Test'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cline/lib/python3.11/site-packages/phoenix/client/resources/datasets/__init__.py:1023\u001b[39m, in \u001b[36mDatasets._process_dataset_upload_response\u001b[39m\u001b[34m(self, response, timeout)\u001b[39m\n\u001b[32m   1022\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cline/lib/python3.11/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '409 Conflict' for url 'https://app.phoenix.arize.com/s/cline-priyan/v1/datasets/upload?sync=true'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatasetUploadError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      3\u001b[39m phoenix_client = Client(base_url=HOSTNAME, api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mPHOENIX_API_KEY\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      5\u001b[39m train_dataset = phoenix_client.datasets.create_dataset(\n\u001b[32m      6\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mCline Act Mode: SWE-bench Train\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     dataset_description=\u001b[33m\"\u001b[39m\u001b[33mCline Act Mode: SWE-bench Train\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     output_keys=[]\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m test_dataset = \u001b[43mphoenix_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCline Act Mode: SWE-bench Test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_description\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCline Act Mode: SWE-bench Test\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_pd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mproblem_statement\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minstance_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest_patch\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cline/lib/python3.11/site-packages/phoenix/client/resources/datasets/__init__.py:732\u001b[39m, in \u001b[36mDatasets.create_dataset\u001b[39m\u001b[34m(self, name, examples, dataframe, csv_file_path, input_keys, output_keys, metadata_keys, inputs, outputs, metadata, dataset_description, timeout)\u001b[39m\n\u001b[32m    730\u001b[39m     table = dataframe \u001b[38;5;28;01mif\u001b[39;00m dataframe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m csv_file_path\n\u001b[32m    731\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_upload_tabular_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_description\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m        \u001b[49m\u001b[43maction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcreate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_json_dataset(\n\u001b[32m    744\u001b[39m         dataset_name=name,\n\u001b[32m    745\u001b[39m         inputs=inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    750\u001b[39m         timeout=timeout,\n\u001b[32m    751\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cline/lib/python3.11/site-packages/phoenix/client/resources/datasets/__init__.py:954\u001b[39m, in \u001b[36mDatasets._upload_tabular_dataset\u001b[39m\u001b[34m(self, table, dataset_name, input_keys, output_keys, metadata_keys, dataset_description, action, timeout)\u001b[39m\n\u001b[32m    937\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mUploading dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    938\u001b[39m response = \u001b[38;5;28mself\u001b[39m._client.post(\n\u001b[32m    939\u001b[39m     url=\u001b[33m\"\u001b[39m\u001b[33mv1/datasets/upload\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    940\u001b[39m     files={\u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m: file},\n\u001b[32m   (...)\u001b[39m\u001b[32m    951\u001b[39m     timeout=timeout,\n\u001b[32m    952\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_dataset_upload_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cline/lib/python3.11/site-packages/phoenix/client/resources/datasets/__init__.py:1029\u001b[39m, in \u001b[36mDatasets._process_dataset_upload_response\u001b[39m\u001b[34m(self, response, timeout)\u001b[39m\n\u001b[32m   1027\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1028\u001b[39m         error_detail = response.text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[32m-> \u001b[39m\u001b[32m1029\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetUploadError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset upload failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_detail\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1031\u001b[39m upload_data = response.json()[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1032\u001b[39m dataset_id = upload_data[\u001b[33m\"\u001b[39m\u001b[33mdataset_id\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mDatasetUploadError\u001b[39m: Dataset upload failed: Dataset with the same name already exists: name='Cline Act Mode: SWE-bench Test'"
     ]
    }
   ],
   "source": [
    "from phoenix.client import Client\n",
    "\n",
    "phoenix_client = Client(base_url=HOSTNAME, api_key=os.getenv(\"PHOENIX_API_KEY\"))\n",
    "\n",
    "train_dataset = phoenix_client.datasets.create_dataset(\n",
    "    name=\"Cline Act Mode: SWE-bench Train\",\n",
    "    dataset_description=\"Cline Act Mode: SWE-bench Train\",\n",
    "    dataframe=train_pd,\n",
    "    input_keys=['problem_statement'],\n",
    "    metadata_keys=['instance_id', 'test_patch'],\n",
    "    output_keys=[]\n",
    ")\n",
    "\n",
    "test_dataset = phoenix_client.datasets.create_dataset(\n",
    "    name=\"Cline Act Mode: SWE-bench Test\",\n",
    "    dataset_description=\"Cline Act Mode: SWE-bench Test\",\n",
    "    dataframe=test_pd,\n",
    "    input_keys=['problem_statement'],\n",
    "    metadata_keys=['instance_id', 'test_patch'],\n",
    "    output_keys=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2df87",
   "metadata": {},
   "source": [
    "## Helper: Log Experiments to Arize\n",
    "\n",
    "This helper function logs experiment results to Arize, allowing us to visualize and track optimization progress across iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0246a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import phoenix_experiments\n",
    "importlib.reload(phoenix_experiments)\n",
    "from phoenix_experiments import log_experiment_to_phoenix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb7a69",
   "metadata": {},
   "source": [
    "## Ruleset Optimization Loop\n",
    "\n",
    "This is the main optimization loop. For each iteration:\n",
    "\n",
    "1. **Run Cline in Act Mode on training set** with the current ruleset, generating actual code patches\n",
    "2. **Run Cline in Act Mode on test set** with the current ruleset to measure generalization\n",
    "3. **Run SWE-bench tests** to validate patches and compute pass/fail metrics\n",
    "4. **Evaluate results** using LLM-as-judge to provide detailed feedback on patch quality\n",
    "5. **Optimize the ruleset** using Prompt Learning based on training results and feedback\n",
    "6. **Save results and rulesets** for tracking and analysis\n",
    "\n",
    "The optimization loop uses actual test execution results (pass/fail) as ground truth, combined with LLM evaluator feedback to iteratively improve the ruleset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37486130",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruleset = \"\"\n",
    "\n",
    "for loop in range(LOOPS):\n",
    "    print(f\"Running for loop: {loop}\")\n",
    "\n",
    "    train_run_id = f\"claude_150_train_{loop}\"\n",
    "    test_run_id = f\"150_act_test_{loop}\"\n",
    "\n",
    "    train_df = run_act(dataset_name=dataset_name, instance_ids=train_ids, run_id=train_run_id, ruleset=ruleset, workers=WORKERS)\n",
    "    test_df = run_act(dataset_name=dataset_name, instance_ids=test_ids, run_id=test_run_id, ruleset=ruleset, workers=WORKERS)\n",
    "\n",
    "    test_df.to_csv(f\"act_results/test_results_{loop}.csv\", index=False)\n",
    "    \n",
    "    train_acc = sum(train_df[\"pass_or_fail\"] == \"pass\") / len(train_df)\n",
    "    test_acc = sum(test_df[\"pass_or_fail\"] == \"pass\") / len(test_df)\n",
    "    print(f\"Train Accuracy: {train_acc}\")\n",
    "    # print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "    # make sure any swebench package installations did not affect phoenix package\n",
    "    subprocess.run([\n",
    "        \"/opt/anaconda3/envs/cline/bin/python3\",\n",
    "        \"-m\",\n",
    "        \"pip\",\n",
    "        \"install\",\n",
    "        \"--upgrade\",\n",
    "        \"arize-phoenix\",\n",
    "        \"wrapt\",\n",
    "    ])\n",
    "    evaluated_train_results = evaluate_results(train_df)\n",
    "    evaluated_train_results.to_csv(f\"act_results/testing_train_results_{loop}.csv\", index=False)\n",
    "    evaluated_train_results[\"score\"] = [1.0 if x == \"correct\" else 0.0 for x in evaluated_train_results[\"correctness\"]]\n",
    "    \n",
    "    # Log experiment to Phoenix using REST API\n",
    "    log_experiment_to_phoenix(\n",
    "        hostname=HOSTNAME,\n",
    "        api_key=os.getenv(\"PHOENIX_API_KEY\"),\n",
    "        dataset_obj=train_dataset,\n",
    "        experiment_name=f\"Train {loop}\",\n",
    "        experiment_df=evaluated_train_results,\n",
    "        metadata={\n",
    "            \"loop\": loop,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"train_size\": TRAIN_SIZE,\n",
    "            \"test_size\": TEST_SIZE\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pl_optimizer = PromptLearningOptimizer(\n",
    "        prompt=CLINE_PROMPT,\n",
    "        model_choice=\"gpt-5\",\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "    ruleset = pl_optimizer.optimize(\n",
    "        dataset=evaluated_train_results,\n",
    "        output_column=\"cline_patch\",\n",
    "        feedback_columns=[\"correctness\", \"explanation\"],\n",
    "        ruleset=ruleset,\n",
    "        context_size_k=400000\n",
    "    )\n",
    "    with open(f\"act_rulesets/ruleset_{loop}.txt\", \"w\") as f:\n",
    "        f.write(f\"train_accuracy: {train_acc} \\n\")\n",
    "        f.write(f\"test_accuracy: {test_acc} \\n\")\n",
    "        f.write(f\"optimized ruleset_{loop}: \\n {ruleset} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pd(numcorrect):\n",
    "    train_pd_1 = train_pd.copy()\n",
    "    train_pd_1[\"cline_patch\"] = train_pd_1[\"test_patch\"]\n",
    "    train_pd_1[\"correctness\"] = [\"correct\"] * numcorrect + [\"incorrect\"] * (150 - numcorrect)\n",
    "    train_pd_1[\"explanation\"] = [\"explanation\"] * 150\n",
    "    return train_pd_1\n",
    "\n",
    "train_pd_1 = create_pd(28)\n",
    "train_pd_2 = create_pd(30)\n",
    "train_pd_3 = create_pd(51)\n",
    "train_pd_4 = create_pd(50)\n",
    "train_pd_5 = create_pd(51)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729409f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 8 fields in line 150, saw 9\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m phoenix_client = Client(base_url=HOSTNAME, api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mPHOENIX_API_KEY\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m train_pd = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mact_results/train_results_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mloop\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m train_dataset = phoenix_client.datasets.create_dataset(\n\u001b[32m      8\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mCline Act Mode: SWE-bench Train\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     dataset_description=\u001b[33m\"\u001b[39m\u001b[33mCline Act Mode: SWE-bench Train\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     output_keys=[]\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m loop = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cline/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cline/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cline/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/cline/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 8 fields in line 150, saw 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for experiment_csv in [\"act_results/train_results_0.csv\", \"act_results/train_results_1.csv\", \"act_results/train_results_2.csv\", \"act_results/train_results_3.csv\", \"act_results/train_results_4.csv\"]:\n",
    "    loop += 1\n",
    "    experiment_df = pd.read_csv(experiment_csv)\n",
    "    log_experiment_to_phoenix(\n",
    "        hostname=HOSTNAME,\n",
    "        api_key=os.getenv(\"PHOENIX_API_KEY\"),\n",
    "        dataset_obj=train_dataset,\n",
    "        experiment_name=f\"Train {loop}\",\n",
    "        experiment_df=experiment_df,\n",
    "        metadata={\n",
    "            \"loop\": loop,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"train_size\": TRAIN_SIZE,\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
